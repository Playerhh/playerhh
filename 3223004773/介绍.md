
## 计算模块接口的设计与实现过程

### 系统架构设计

本论文查重系统采用模块化设计，主要包含以下几个核心模块：

1. **文件处理模块**：负责读取原文和抄袭版文件内容
2. **文本预处理模块**：进行大小写转换和标点符号去除
3. **n-gram生成模块**：将文本分割为固定长度的字符片段
4. **哈希表管理模块**：高效存储和查询n-gram特征
5. **相似度计算模块**：基于Jaccard系数计算文本相似度
6. **结果输出模块**：将结果写入指定文件

### 核心数据结构

```c
// n-gram节点结构
typedef struct NGramNode {
    char gram[N_GRAM + 1];  // n-gram字符串
    int count;              // 出现次数
    struct NGramNode *next; // 下一个节点（处理哈希冲突）
} NGramNode;

// 哈希表结构
typedef struct {
    NGramNode **table;      // 哈希表数组
    int size;               // 哈希表大小
} HashTable;
```
###关键算法流程
####n-gram生成算法
输入: 预处理后的文本字符串
输出: 包含所有n-gram的哈希表

1. 初始化空哈希表
2. 使用滑动窗口遍历文本
3. 对于每个位置，提取长度为N的子串
4. 将子串插入哈希表（已存在则计数+1，否则新建节点）
5. 返回填充完成的哈希表

####Jaccard相似度计算
Jaccard(A,B) = |A ∩ B| / |A ∪ B|
= |A ∩ B| / (|A| + |B| - |A ∩ B|)

其中：
- A ∩ B: 两个文本共有的n-gram数量（取最小计数）
- A ∪ B: 两个文本所有n-gram的数量总和
#####独到之处
高效的哈希表设计：使用DJB2哈希算法和链表法解决冲突，保证O(1)的平均查找时间

内存优化：通过合理的结构设计和内存管理，避免内存泄漏
中文支持：特殊处理中文字符，避免误判
容错性强：对空文件和异常输入有良好的处理机制
###计算模块接口部分的性能改进
####性能优化策略
在开发过程中，我主要从以下几个方面进行了性能优化：

哈希表大小选择：使用质数100003作为哈希表大小，减少哈希冲突

内存预分配：一次性读取文件内容，避免频繁的I/O操作

算法优化：使用高效的DJB2哈希算法，提高查找速度

循环优化：减少不必要的循环和函数调用
####性能分析
使用gprof工具进行性能分析，得到以下结果：



```c```
###计算模块部分单元测试展示
